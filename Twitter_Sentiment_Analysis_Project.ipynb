{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, min, max\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "\n",
    "PATH = r\"C:\\Users\\cuong\\2021 Machine Learning\\data\"\n",
    "conf = SparkConf().setAppName(\"CIS5367 Midterm App\").setMaster(\"local\")\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)\n",
    "sql_context = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    twitter_data = sql_context.read.load(\"%s/twitter_10k_data.csv\" % PATH,    \n",
    "                      format='com.databricks.spark.csv', \n",
    "                      header='true', \n",
    "                      inferSchema='true')\n",
    "    #Delete all duplicated rows\n",
    "    #twitter_data = twitter_data.distinct()\n",
    "    \n",
    "    #Return a dataframe\n",
    "    return twitter_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Dataset and divide it into training and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when \n",
    "twitter_data = twitter_data.withColumn('polarity_type', when(twitter_data.polarity > 0, 'positive')\\\n",
    "                                         .when(twitter_data.polarity < 0, 'negative').otherwise(\"neutral\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(polarity=-1.0, tweet='AskNationwide Hermesparcels Hermes out of all the delivery companies in UK u are by the worst hence why we b', brand_name='Hermes', polarity_type='negative')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.sql.functions import udf, lit\n",
    "from pyspark.sql.types import StringType, ArrayType\n",
    "\n",
    "\n",
    "(df_train_raw, df_test_raw) = twitter_data.randomSplit([0.8, 0.2], seed = 1234)\n",
    "print (df_train_raw.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Count:::::  1836\n",
      "\n",
      "Train Count:::::  7433\n"
     ]
    }
   ],
   "source": [
    "print (\"\\nTest Count::::: \" , df_test_raw.count())\n",
    "print (\"\\nTrain Count::::: \" , df_train_raw.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+----------+-------------+----+\n",
      "|           polarity|               tweet|brand_name|polarity_type|part|\n",
      "+-------------------+--------------------+----------+-------------+----+\n",
      "|               -1.0|AskNationwide Her...|    Hermes|     negative|   1|\n",
      "|              -0.85|Horrible And Ugly...|     Gucci|     negative|   1|\n",
      "|               -0.8|Hate when this ha...|     Gucci|     negative|   1|\n",
      "|-0.6999999999999998|Gary Effin Oldman...|     Prada|     negative|   1|\n",
      "|-0.6999999999999998|NewNew vaporwave ...|     Fendi|     negative|   1|\n",
      "|               -0.6|Altri 10 minuti A...|     Gucci|     negative|   1|\n",
      "|               -0.6|Body bagprada are...|     Prada|     negative|   1|\n",
      "|               -0.6|Guccis armed and ...|     Gucci|     negative|   1|\n",
      "|               -0.6|Hermesparcels is ...|    Hermes|     negative|   1|\n",
      "|               -0.6|Something in betw...|  Burberry|     negative|   1|\n",
      "|               -0.6|Versace Stone col...|   Versace|     negative|   1|\n",
      "|               -0.6|jayrayner1 Keep t...|    Hermes|     negative|   1|\n",
      "|               -0.6|windy cold i thou...|    Chanel|     negative|   1|\n",
      "|-0.5999999999999999|Hermesparcels how...|    Hermes|     negative|   1|\n",
      "|-0.5333333333333333|I needed to fall ...|      Polo|     negative|   1|\n",
      "|-0.5000000000000001|ABOUTLASTNIGHT tr...|   Versace|     negative|   1|\n",
      "|-0.5000000000000001|Casual lookstreet...|    Chanel|     negative|   1|\n",
      "|-0.5000000000000001|Check out Polo Ra...|      Polo|     negative|   1|\n",
      "|-0.5000000000000001|Check out Polo Ra...|      Polo|     negative|   1|\n",
      "|-0.5000000000000001|Just casual lifea...|     Gucci|     negative|   1|\n",
      "+-------------------+--------------------+----------+-------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train_raw = df_train_raw.withColumn(\"part\", lit(1))\n",
    "df_test_raw = df_test_raw.withColumn(\"part\", lit(0))\n",
    "df_all_raw = df_train_raw.union(df_test_raw)\n",
    "df_all_raw.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data - eliminate unneccessary words, create word counts by converts texts into vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing Data\n",
    "tokenizer = Tokenizer(inputCol='tweet', outputCol='words')\n",
    "wordsData = tokenizer.transform(df_all_raw). \\\n",
    "    select('polarity_type', 'brand_name', 'words', 'part')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove number\n",
    "filter = re.compile(r\"^[a-zA-Z]+$\")\n",
    "match_udf = udf(lambda tokens: [token for token in tokens if filter.match(token)], ArrayType(StringType()))\n",
    "df_matched = wordsData.withColumn(\"words_matched\", match_udf(\"words\")). \\\n",
    "    select('words_matched', 'polarity_type', 'brand_name','part')\n",
    "# Remove stop words\n",
    "remover = StopWordsRemover(inputCol='words_matched', outputCol='words_clean')\n",
    "df_words_clean = remover.transform(df_matched). \\\n",
    "    select('words_clean', 'polarity_type', 'part','brand_name')\n",
    "#print(df_words_clean.show(5))\n",
    "# Stem text\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "stemmer_udf = udf(lambda tokens: [stemmer.stem(token) for token in tokens], ArrayType(StringType()))\n",
    "df_stemmed = df_words_clean.withColumn(\"words_stemmed\", stemmer_udf(\"words_clean\")). \\\n",
    "    select('words_stemmed', 'polarity_type', 'part','brand_name')\n",
    "    \n",
    "#df_stemmed.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+----+----------+--------------------+--------------------+---------------+--------------+\n",
      "|       words_stemmed|polarity_type|part|brand_name|         rawFeatures|            features|brandname_index|polarity_index|\n",
      "+--------------------+-------------+----+----------+--------------------+--------------------+---------------+--------------+\n",
      "|[asknationwid, he...|     negative|   1|    Hermes|(262144,[47552,51...|(262144,[47552,51...|            5.0|           2.0|\n",
      "|[horribl, ugli, g...|     negative|   1|     Gucci|(262144,[22675,34...|(262144,[22675,34...|            0.0|           2.0|\n",
      "|[hate, happen, gu...|     negative|   1|     Gucci|(262144,[72709,12...|(262144,[72709,12...|            0.0|           2.0|\n",
      "|[gari, effin, old...|     negative|   1|     Prada|(262144,[3924,175...|(262144,[3924,175...|            3.0|           2.0|\n",
      "|[newnew, vaporwav...|     negative|   1|     Fendi|(262144,[17734,20...|(262144,[17734,20...|            6.0|           2.0|\n",
      "|[altri, minuti, f...|     negative|   1|     Gucci|(262144,[88500,10...|(262144,[88500,10...|            0.0|           2.0|\n",
      "|[bodi, bagprada, ...|     negative|   1|     Prada|(262144,[5451,994...|(262144,[5451,994...|            3.0|           2.0|\n",
      "|[gucci, arm, dang...|     negative|   1|     Gucci|(262144,[1968,365...|(262144,[1968,365...|            0.0|           2.0|\n",
      "|[hermesparcel, wo...|     negative|   1|    Hermes|(262144,[1696,538...|(262144,[1696,538...|            5.0|           2.0|\n",
      "|[someth, soldier,...|     negative|   1|  Burberry|(262144,[33835,39...|(262144,[33835,39...|            1.0|           2.0|\n",
      "|[versac, stone, c...|     negative|   1|   Versace|(262144,[661,3128...|(262144,[661,3128...|            7.0|           2.0|\n",
      "|[keep, lecreuset,...|     negative|   1|    Hermes|(262144,[9129,328...|(262144,[9129,328...|            5.0|           2.0|\n",
      "|[windi, cold, tho...|     negative|   1|    Chanel|(262144,[24016,89...|(262144,[24016,89...|            2.0|           2.0|\n",
      "|[hermesparcel, su...|     negative|   1|    Hermes|(262144,[6122,618...|(262144,[6122,618...|            5.0|           2.0|\n",
      "|[need, fall, asle...|     negative|   1|      Polo|(262144,[15099,18...|(262144,[15099,18...|            4.0|           2.0|\n",
      "|[aboutlastnight, ...|     negative|   1|   Versace|(262144,[1747,100...|(262144,[1747,100...|            7.0|           2.0|\n",
      "|[casual, lookstre...|     negative|   1|    Chanel|(262144,[2317,162...|(262144,[2317,162...|            2.0|           2.0|\n",
      "|[check, polo, ral...|     negative|   1|      Polo|(262144,[14273,18...|(262144,[14273,18...|            4.0|           2.0|\n",
      "|[check, polo, ral...|     negative|   1|      Polo|(262144,[14273,18...|(262144,[14273,18...|            4.0|           2.0|\n",
      "|[casual, lifeasle...|     negative|   1|     Gucci|(262144,[28918,32...|(262144,[28918,32...|            0.0|           2.0|\n",
      "+--------------------+-------------+----+----------+--------------------+--------------------+---------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "# tf-idf\n",
    "hashingTF = HashingTF(inputCol=\"words_stemmed\", outputCol=\"rawFeatures\") #generate vectors\n",
    "featurizedData = hashingTF.transform(df_stemmed)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "#rescaledData.show()\n",
    "\n",
    "#Add Brand_name -- group_index to the dataset\n",
    "brandname_indexer = StringIndexer(inputCol=\"brand_name\", outputCol=\"brandname_index\")\n",
    "df_brandname_indexed = brandname_indexer.fit(rescaledData).transform(rescaledData)\n",
    "\n",
    "#Add polarity_type --polarity_index to the dataset\n",
    "polarity_indexer = StringIndexer(inputCol=\"polarity_type\", outputCol=\"polarity_index\")\n",
    "df_two_indexed = polarity_indexer.fit(df_brandname_indexed).transform(df_brandname_indexed) \n",
    "df_two_indexed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+----+----------+--------------------+--------------------+---------------+--------------+--------------------+\n",
      "|       words_stemmed|polarity_type|part|brand_name|         rawFeatures|            features|brandname_index|polarity_index|      final_features|\n",
      "+--------------------+-------------+----+----------+--------------------+--------------------+---------------+--------------+--------------------+\n",
      "|[asknationwid, he...|     negative|   1|    Hermes|(262144,[47552,51...|(262144,[47552,51...|            5.0|           2.0|(262145,[47552,51...|\n",
      "|[horribl, ugli, g...|     negative|   1|     Gucci|(262144,[22675,34...|(262144,[22675,34...|            0.0|           2.0|(262145,[22675,34...|\n",
      "|[hate, happen, gu...|     negative|   1|     Gucci|(262144,[72709,12...|(262144,[72709,12...|            0.0|           2.0|(262145,[72709,12...|\n",
      "|[gari, effin, old...|     negative|   1|     Prada|(262144,[3924,175...|(262144,[3924,175...|            3.0|           2.0|(262145,[3924,175...|\n",
      "|[newnew, vaporwav...|     negative|   1|     Fendi|(262144,[17734,20...|(262144,[17734,20...|            6.0|           2.0|(262145,[17734,20...|\n",
      "|[altri, minuti, f...|     negative|   1|     Gucci|(262144,[88500,10...|(262144,[88500,10...|            0.0|           2.0|(262145,[88500,10...|\n",
      "|[bodi, bagprada, ...|     negative|   1|     Prada|(262144,[5451,994...|(262144,[5451,994...|            3.0|           2.0|(262145,[5451,994...|\n",
      "|[gucci, arm, dang...|     negative|   1|     Gucci|(262144,[1968,365...|(262144,[1968,365...|            0.0|           2.0|(262145,[1968,365...|\n",
      "|[hermesparcel, wo...|     negative|   1|    Hermes|(262144,[1696,538...|(262144,[1696,538...|            5.0|           2.0|(262145,[1696,538...|\n",
      "|[someth, soldier,...|     negative|   1|  Burberry|(262144,[33835,39...|(262144,[33835,39...|            1.0|           2.0|(262145,[33835,39...|\n",
      "|[versac, stone, c...|     negative|   1|   Versace|(262144,[661,3128...|(262144,[661,3128...|            7.0|           2.0|(262145,[661,3128...|\n",
      "|[keep, lecreuset,...|     negative|   1|    Hermes|(262144,[9129,328...|(262144,[9129,328...|            5.0|           2.0|(262145,[9129,328...|\n",
      "|[windi, cold, tho...|     negative|   1|    Chanel|(262144,[24016,89...|(262144,[24016,89...|            2.0|           2.0|(262145,[24016,89...|\n",
      "|[hermesparcel, su...|     negative|   1|    Hermes|(262144,[6122,618...|(262144,[6122,618...|            5.0|           2.0|(262145,[6122,618...|\n",
      "|[need, fall, asle...|     negative|   1|      Polo|(262144,[15099,18...|(262144,[15099,18...|            4.0|           2.0|(262145,[15099,18...|\n",
      "|[aboutlastnight, ...|     negative|   1|   Versace|(262144,[1747,100...|(262144,[1747,100...|            7.0|           2.0|(262145,[1747,100...|\n",
      "|[casual, lookstre...|     negative|   1|    Chanel|(262144,[2317,162...|(262144,[2317,162...|            2.0|           2.0|(262145,[2317,162...|\n",
      "|[check, polo, ral...|     negative|   1|      Polo|(262144,[14273,18...|(262144,[14273,18...|            4.0|           2.0|(262145,[14273,18...|\n",
      "|[check, polo, ral...|     negative|   1|      Polo|(262144,[14273,18...|(262144,[14273,18...|            4.0|           2.0|(262145,[14273,18...|\n",
      "|[casual, lifeasle...|     negative|   1|     Gucci|(262144,[28918,32...|(262144,[28918,32...|            0.0|           2.0|(262145,[28918,32...|\n",
      "+--------------------+-------------+----+----------+--------------------+--------------------+---------------+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Input features for Baynesian Methods is the combination of word counts and sentiments\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=[\"rawFeatures\",\"polarity_index\"],outputCol=\"final_features\")\n",
    "assemblerData = assembler.transform(df_two_indexed)\n",
    "assemblerData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+----+----------+--------------------+--------------------+---------------+--------------+--------------------+\n",
      "|       words_stemmed|polarity_type|part|brand_name|         rawFeatures|            features|brandname_index|polarity_index|      final_features|\n",
      "+--------------------+-------------+----+----------+--------------------+--------------------+---------------+--------------+--------------------+\n",
      "|[polo, time, brut...|     negative|   0|      Polo|(262144,[18536,43...|(262144,[18536,43...|            4.0|           2.0|(262145,[18536,43...|\n",
      "|[herm, worst, del...|     negative|   0|    Hermes|(262144,[21823,11...|(262144,[21823,11...|            5.0|           2.0|(262145,[21823,11...|\n",
      "|[check, polo, ral...|     negative|   0|      Polo|(262144,[14273,18...|(262144,[14273,18...|            4.0|           2.0|(262145,[14273,18...|\n",
      "|[rt, streetstylep...|     negative|   0|    Chanel|(262144,[2317,162...|(262144,[2317,162...|            2.0|           2.0|(262145,[2317,162...|\n",
      "|[style, fashionkh...|     negative|   0|     Gucci|(262144,[33947,36...|(262144,[33947,36...|            0.0|           2.0|(262145,[33947,36...|\n",
      "|[style, fashionkh...|     negative|   0|     Fendi|(262144,[33947,48...|(262144,[33947,48...|            6.0|           2.0|(262145,[33947,48...|\n",
      "|[style, fashionkh...|     negative|   0|   Versace|(262144,[33947,48...|(262144,[33947,48...|            7.0|           2.0|(262145,[33947,48...|\n",
      "|[spot, fake, prad...|     negative|   0|     Prada|(262144,[53800,72...|(262144,[53800,72...|            3.0|           2.0|(262145,[53800,72...|\n",
      "|[rt, wandell, yal...|     negative|   0|    Chanel|(262144,[21823,46...|(262144,[21823,46...|            2.0|           2.0|(262145,[21823,46...|\n",
      "|[rt, luvkwamii, d...|     negative|   0|   Versace|(262144,[661,2622...|(262144,[661,2622...|            7.0|           2.0|(262145,[661,2622...|\n",
      "|[rt, sorri, got, ...|     negative|   0|    Chanel|(262144,[38751,77...|(262144,[38751,77...|            2.0|           2.0|(262145,[38751,77...|\n",
      "|[rt, part, exo, c...|     negative|   0|     Prada|(262144,[8804,342...|(262144,[8804,342...|            3.0|           2.0|(262145,[8804,342...|\n",
      "|[sorri, got, ask,...|     negative|   0|    Chanel|(262144,[38751,90...|(262144,[38751,90...|            2.0|           2.0|(262145,[38751,90...|\n",
      "|[medium, chanel, ...|     negative|   0|    Chanel|(262144,[25882,26...|(262144,[25882,26...|            2.0|           2.0|(262145,[25882,26...|\n",
      "|[know, im, late, ...|     negative|   0|   Versace|(262144,[31015,58...|(262144,[31015,58...|            7.0|           2.0|(262145,[31015,58...|\n",
      "|[behind, scene, s...|     negative|   0|    Chanel|(262144,[59114,68...|(262144,[59114,68...|            2.0|           2.0|(262145,[59114,68...|\n",
      "|[rt, behind, scen...|     negative|   0|    Chanel|(262144,[35652,59...|(262144,[35652,59...|            2.0|           2.0|(262145,[35652,59...|\n",
      "|[rt, jonginsmanbu...|     negative|   0|     Gucci|(262144,[21319,64...|(262144,[21319,64...|            0.0|           2.0|(262145,[21319,64...|\n",
      "|[ask, herm, feedb...|     negative|   0|    Hermes|(262144,[68538,77...|(262144,[68538,77...|            5.0|           2.0|(262145,[68538,77...|\n",
      "|[rt, xxfablifexx,...|     negative|   0|    Chanel|(262144,[77407,10...|(262144,[77407,10...|            2.0|           2.0|(262145,[77407,10...|\n",
      "+--------------------+-------------+----+----------+--------------------+--------------------+---------------+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train = assemblerData.where(\"part = 1\")\n",
    "df_test = assemblerData.where(\"part = 0\")\n",
    "df_test.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Naive Bayes Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Model: labelCol is brandname_index and input is the combination of word counts + polarity_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes classifier- first model\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "   \n",
    "nb = NaiveBayes(labelCol=\"brandname_index\",\\\n",
    "    featuresCol=\"final_features\", smoothing=1.0,\\\n",
    "    modelType=\"multinomial\")\n",
    "model = nb.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+---------------+--------------------+----------+\n",
      "|polarity_type|brand_name|brandname_index|         probability|prediction|\n",
      "+-------------+----------+---------------+--------------------+----------+\n",
      "|     negative|      Polo|            4.0|[0.06423671181093...|       4.0|\n",
      "|     negative|    Hermes|            5.0|[1.78528608844415...|       5.0|\n",
      "|     negative|      Polo|            4.0|[7.05890219120392...|       4.0|\n",
      "|     negative|    Chanel|            2.0|[0.76436301294699...|       0.0|\n",
      "|     negative|     Gucci|            0.0|[0.99847874282522...|       0.0|\n",
      "|     negative|     Fendi|            6.0|[0.67166515625544...|       0.0|\n",
      "|     negative|   Versace|            7.0|[0.67166515625544...|       0.0|\n",
      "|     negative|     Prada|            3.0|[0.41127766385035...|       3.0|\n",
      "|     negative|    Chanel|            2.0|[0.81652580577398...|       0.0|\n",
      "|     negative|   Versace|            7.0|[0.99667385868837...|       0.0|\n",
      "|     negative|    Chanel|            2.0|[2.46793267011473...|       2.0|\n",
      "|     negative|     Prada|            3.0|[0.99818861591282...|       0.0|\n",
      "|     negative|    Chanel|            2.0|[7.46700684138640...|       2.0|\n",
      "|     negative|    Chanel|            2.0|[0.02043174236705...|       2.0|\n",
      "|     negative|   Versace|            7.0|[0.99737138823564...|       0.0|\n",
      "|     negative|    Chanel|            2.0|[0.99985625160064...|       0.0|\n",
      "|     negative|    Chanel|            2.0|[0.99992641494777...|       0.0|\n",
      "|     negative|     Gucci|            0.0|[0.99999998920576...|       0.0|\n",
      "|     negative|    Hermes|            5.0|[0.00510043460154...|       5.0|\n",
      "|     negative|    Chanel|            2.0|[2.93350257197630...|       2.0|\n",
      "+-------------+----------+---------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Test set accuracy = 0.8033769063180828\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "predictions = model.transform(df_test)\n",
    "predictions.select(\"polarity_type\",\"brand_name\", \"brandname_index\", \n",
    "    \"probability\", \"prediction\").show()\n",
    "evaluator =\\\n",
    "    MulticlassClassificationEvaluator(labelCol=\"brandname_index\",\\\n",
    "    predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Model: labelCol is polarity_index and input is the combination of word counts + polarity_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input features for Baynesian Methods is the combination of word counts and sentiments\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=[\"rawFeatures\",\"polarity_index\"],outputCol=\"final_features\")\n",
    "assemblerData = assembler.transform(df_two_indexed)\n",
    "#assemblerData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+----+----------+--------------------+--------------------+---------------+--------------+--------------------+\n",
      "|       words_stemmed|polarity_type|part|brand_name|         rawFeatures|            features|brandname_index|polarity_index|      final_features|\n",
      "+--------------------+-------------+----+----------+--------------------+--------------------+---------------+--------------+--------------------+\n",
      "|[polo, time, brut...|     negative|   0|      Polo|(262144,[18536,43...|(262144,[18536,43...|            4.0|           2.0|(262145,[18536,43...|\n",
      "|[herm, worst, del...|     negative|   0|    Hermes|(262144,[21823,11...|(262144,[21823,11...|            5.0|           2.0|(262145,[21823,11...|\n",
      "|[check, polo, ral...|     negative|   0|      Polo|(262144,[14273,18...|(262144,[14273,18...|            4.0|           2.0|(262145,[14273,18...|\n",
      "|[rt, streetstylep...|     negative|   0|    Chanel|(262144,[2317,162...|(262144,[2317,162...|            2.0|           2.0|(262145,[2317,162...|\n",
      "|[style, fashionkh...|     negative|   0|     Gucci|(262144,[33947,36...|(262144,[33947,36...|            0.0|           2.0|(262145,[33947,36...|\n",
      "|[style, fashionkh...|     negative|   0|     Fendi|(262144,[33947,48...|(262144,[33947,48...|            6.0|           2.0|(262145,[33947,48...|\n",
      "|[style, fashionkh...|     negative|   0|   Versace|(262144,[33947,48...|(262144,[33947,48...|            7.0|           2.0|(262145,[33947,48...|\n",
      "|[spot, fake, prad...|     negative|   0|     Prada|(262144,[53800,72...|(262144,[53800,72...|            3.0|           2.0|(262145,[53800,72...|\n",
      "|[rt, wandell, yal...|     negative|   0|    Chanel|(262144,[21823,46...|(262144,[21823,46...|            2.0|           2.0|(262145,[21823,46...|\n",
      "|[rt, luvkwamii, d...|     negative|   0|   Versace|(262144,[661,2622...|(262144,[661,2622...|            7.0|           2.0|(262145,[661,2622...|\n",
      "|[rt, sorri, got, ...|     negative|   0|    Chanel|(262144,[38751,77...|(262144,[38751,77...|            2.0|           2.0|(262145,[38751,77...|\n",
      "|[rt, part, exo, c...|     negative|   0|     Prada|(262144,[8804,342...|(262144,[8804,342...|            3.0|           2.0|(262145,[8804,342...|\n",
      "|[sorri, got, ask,...|     negative|   0|    Chanel|(262144,[38751,90...|(262144,[38751,90...|            2.0|           2.0|(262145,[38751,90...|\n",
      "|[medium, chanel, ...|     negative|   0|    Chanel|(262144,[25882,26...|(262144,[25882,26...|            2.0|           2.0|(262145,[25882,26...|\n",
      "|[know, im, late, ...|     negative|   0|   Versace|(262144,[31015,58...|(262144,[31015,58...|            7.0|           2.0|(262145,[31015,58...|\n",
      "|[behind, scene, s...|     negative|   0|    Chanel|(262144,[59114,68...|(262144,[59114,68...|            2.0|           2.0|(262145,[59114,68...|\n",
      "|[rt, behind, scen...|     negative|   0|    Chanel|(262144,[35652,59...|(262144,[35652,59...|            2.0|           2.0|(262145,[35652,59...|\n",
      "|[rt, jonginsmanbu...|     negative|   0|     Gucci|(262144,[21319,64...|(262144,[21319,64...|            0.0|           2.0|(262145,[21319,64...|\n",
      "|[ask, herm, feedb...|     negative|   0|    Hermes|(262144,[68538,77...|(262144,[68538,77...|            5.0|           2.0|(262145,[68538,77...|\n",
      "|[rt, xxfablifexx,...|     negative|   0|    Chanel|(262144,[77407,10...|(262144,[77407,10...|            2.0|           2.0|(262145,[77407,10...|\n",
      "+--------------------+-------------+----+----------+--------------------+--------------------+---------------+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train = assemblerData.where(\"part = 1\")\n",
    "df_test = assemblerData.where(\"part = 0\")\n",
    "df_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes classifier- first model\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "   \n",
    "nb = NaiveBayes(labelCol=\"polarity_index\",\\\n",
    "    featuresCol=\"final_features\", smoothing=1.0,\\\n",
    "    modelType=\"multinomial\")\n",
    "model = nb.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+--------------+--------------------+----------+\n",
      "|polarity_type|brand_name|polarity_index|         probability|prediction|\n",
      "+-------------+----------+--------------+--------------------+----------+\n",
      "|     negative|      Polo|           2.0|[6.98134381372224...|       1.0|\n",
      "|     negative|    Hermes|           2.0|[7.40915045713100...|       1.0|\n",
      "|     negative|      Polo|           2.0|[5.77339057567219...|       1.0|\n",
      "|     negative|    Chanel|           2.0|[1.95452890835155...|       1.0|\n",
      "|     negative|     Gucci|           2.0|[9.71870774473052...|       1.0|\n",
      "|     negative|     Fendi|           2.0|[2.30365159947401...|       1.0|\n",
      "|     negative|   Versace|           2.0|[2.30365159947401...|       1.0|\n",
      "|     negative|     Prada|           2.0|[8.33852723625867...|       1.0|\n",
      "|     negative|    Chanel|           2.0|[1.50780810357774...|       1.0|\n",
      "|     negative|   Versace|           2.0|[2.39853841554240...|       1.0|\n",
      "|     negative|    Chanel|           2.0|[1.72888175448548...|       2.0|\n",
      "|     negative|     Prada|           2.0|[2.13834098619917...|       1.0|\n",
      "|     negative|    Chanel|           2.0|[1.98139392656777...|       2.0|\n",
      "|     negative|    Chanel|           2.0|[7.3549031720678E...|       1.0|\n",
      "|     negative|   Versace|           2.0|[1.07731424132649...|       1.0|\n",
      "|     negative|    Chanel|           2.0|[2.58809253803554...|       1.0|\n",
      "|     negative|    Chanel|           2.0|[5.59815449601055...|       1.0|\n",
      "|     negative|     Gucci|           2.0|[7.32093325040668...|       1.0|\n",
      "|     negative|    Hermes|           2.0|[5.39191993923872...|       1.0|\n",
      "|     negative|    Chanel|           2.0|[2.11500177419460...|       1.0|\n",
      "+-------------+----------+--------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Test set accuracy = 0.9014161220043573\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "predictions = model.transform(df_test)\n",
    "predictions.select(\"polarity_type\",\"brand_name\", \"polarity_index\", \n",
    "    \"probability\", \"prediction\").show()\n",
    "evaluator =\\\n",
    "    MulticlassClassificationEvaluator(labelCol=\"polarity_index\",\\\n",
    "    predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Model: labelCol is polarity_index and input is word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes classifier- first model\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "   \n",
    "nb = NaiveBayes(labelCol=\"polarity_index\",\\\n",
    "    featuresCol=\"features\", smoothing=1.0,\\\n",
    "    modelType=\"multinomial\")\n",
    "model = nb.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+--------------+--------------------+----------+\n",
      "|polarity_type|brand_name|polarity_index|         probability|prediction|\n",
      "+-------------+----------+--------------+--------------------+----------+\n",
      "|     negative|      Polo|           2.0|[3.49094951721355...|       2.0|\n",
      "|     negative|    Hermes|           2.0|[2.74372952323274...|       2.0|\n",
      "|     negative|      Polo|           2.0|[0.99933799049672...|       0.0|\n",
      "|     negative|    Chanel|           2.0|[2.12425146849372...|       2.0|\n",
      "|     negative|     Gucci|           2.0|[2.55025346740856...|       2.0|\n",
      "|     negative|     Fendi|           2.0|[8.32191895103603...|       2.0|\n",
      "|     negative|   Versace|           2.0|[8.32191895103603...|       2.0|\n",
      "|     negative|     Prada|           2.0|[0.99999996684710...|       0.0|\n",
      "|     negative|    Chanel|           2.0|[2.44948510931897...|       2.0|\n",
      "|     negative|   Versace|           2.0|[7.89191800398136...|       2.0|\n",
      "|     negative|    Chanel|           2.0|[1.29355367330149...|       2.0|\n",
      "|     negative|     Prada|           2.0|[7.95745772479853...|       1.0|\n",
      "|     negative|    Chanel|           2.0|[3.75538160368239...|       2.0|\n",
      "|     negative|    Chanel|           2.0|[8.58773993452031...|       2.0|\n",
      "|     negative|   Versace|           2.0|[6.61293240121011...|       2.0|\n",
      "|     negative|    Chanel|           2.0|[1.53805975498708...|       1.0|\n",
      "|     negative|    Chanel|           2.0|[2.08717807813157...|       1.0|\n",
      "|     negative|     Gucci|           2.0|[2.86446557864691...|       2.0|\n",
      "|     negative|    Hermes|           2.0|[8.26179952671335...|       2.0|\n",
      "|     negative|    Chanel|           2.0|[2.12938148579382...|       2.0|\n",
      "+-------------+----------+--------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Test set accuracy = 0.914488017429194\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "predictions = model.transform(df_test)\n",
    "predictions.select(\"polarity_type\",\"brand_name\", \"polarity_index\", \n",
    "    \"probability\", \"prediction\").show()\n",
    "evaluator =\\\n",
    "    MulticlassClassificationEvaluator(labelCol=\"polarity_index\",\\\n",
    "    predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth Model: labelCol is brandname_index and input is word count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes classifier- first model\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "   \n",
    "nb = NaiveBayes(labelCol=\"brandname_index\",\\\n",
    "    featuresCol=\"features\", smoothing=1.0,\\\n",
    "    modelType=\"multinomial\")\n",
    "model = nb.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+--------------------+----------+\n",
      "|polarity_type|brand_name|         probability|prediction|\n",
      "+-------------+----------+--------------------+----------+\n",
      "|     negative|      Polo|[5.13502975449590...|       7.0|\n",
      "|     negative|    Hermes|[1.34003442010529...|       5.0|\n",
      "|     negative|      Polo|[9.51750306823672...|       4.0|\n",
      "|     negative|    Chanel|[1.39967076474221...|       2.0|\n",
      "|     negative|     Gucci|[7.95698730216830...|       6.0|\n",
      "|     negative|     Fendi|[0.73065398400100...|       0.0|\n",
      "|     negative|   Versace|[0.73065398400100...|       0.0|\n",
      "|     negative|     Prada|[0.99999486808278...|       0.0|\n",
      "|     negative|    Chanel|[0.99999999954300...|       0.0|\n",
      "|     negative|   Versace|[2.90388333498720...|       7.0|\n",
      "|     negative|    Chanel|[1.80308467906069...|       2.0|\n",
      "|     negative|     Prada|[0.99999999293150...|       0.0|\n",
      "|     negative|    Chanel|[9.02171884292929...|       2.0|\n",
      "|     negative|    Chanel|[1.71682763907247...|       2.0|\n",
      "|     negative|   Versace|[0.99999989052556...|       0.0|\n",
      "|     negative|    Chanel|[1.0,8.9738038278...|       0.0|\n",
      "|     negative|    Chanel|[1.0,1.8688801763...|       0.0|\n",
      "|     negative|     Gucci|[1.0,3.1201534301...|       0.0|\n",
      "|     negative|    Hermes|[2.53362079452902...|       5.0|\n",
      "|     negative|    Chanel|[3.35384396807011...|       2.0|\n",
      "+-------------+----------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Test set accuracy = 0.789760348583878\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "predictions = model.transform(df_test)\n",
    "predictions.select(\"polarity_type\",\"brand_name\", \n",
    "    \"probability\", \"prediction\").show()\n",
    "evaluator =\\\n",
    "    MulticlassClassificationEvaluator(labelCol=\"brandname_index\",\\\n",
    "    predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
